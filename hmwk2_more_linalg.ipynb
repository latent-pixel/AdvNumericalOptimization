{"cells":[{"cell_type":"markdown","metadata":{"id":"tNgUk1bET6rD"},"source":["Name:  **Bhargav Kumar Soothram**  \n","UID:  **117041088**"]},{"cell_type":"markdown","metadata":{"id":"HwLk2iSHT6rL"},"source":["# Homework 2:  More Linear Algebra "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EJseNRd7T6rM"},"outputs":[],"source":["# Setup the environment - do not modify this cell, but run it before anything else\n","import numpy as np\n","from scipy.signal import convolve2d\n","from scipy.linalg import hilbert\n","from numpy.random import randn, normal\n","from numpy.linalg import norm, inv\n","from numpy.fft import fft2, ifft2\n","import urllib\n","import matplotlib.pyplot as plt\n","np.random.seed(0)"]},{"cell_type":"markdown","metadata":{"id":"TtEhCL2gT6rP"},"source":["## Problem 1 - condition number\n","Run the following code.  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E38TDc1PT6rQ","executionInfo":{"status":"ok","timestamp":1680181886300,"user_tz":240,"elapsed":241,"user":{"displayName":"Bhargav Kumar Soothram","userId":"14130805473074256710"}},"outputId":"9add5225-3cd9-4947-a390-f4bdd6c23dc5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Recovery error (clean) = 2.71e-06\n","measurement error = 1.79e-07\n","Recovery error (noisy) = 178.930\n"]}],"source":["# Do not modify this block!\n","# Create a linear system Ax=b\n","n=8\n","A = hilbert(n)      # construct an n by n matrix\n","x = randn(n,1)      # construct n by 1 signal \n","b = A@x             # Note that '@' is matrix multiplication in python, while '*' denotes entry-wise multiplication\n","\n","# Solve the system to recover x\n","x_recovered = inv(A)@b \n","print('Recovery error (clean) = %0.3g'%norm(x_recovered-x))\n","\n","# Add some noise\n","b_noise = b+randn(n,1)*0.0000001\n","print('measurement error = %0.3g'%norm(b_noise-b))\n","\n","# Solve the noisy system\n","x_noise = inv(A)@b_noise\n","print('Recovery error (noisy) = %0.3f'%norm(x_noise-x))\n"]},{"cell_type":"markdown","metadata":{"id":"NJ-nNyjlT6rT"},"source":["### Why did this happen?   Write a few sentences.\n","We need to think about why the recovery error corresponding to x varies significantly even when a very small amount of noise is added to the measurement b. This variation can be gauged by the condition number $\\kappa$ of the system. $\\kappa$ is the ratio of the maximum eigen value to the minimum eigen value of the system. This is used to measure how sensitive a function is to changes or errors in the input, and how much error in the output results from an error in the input. If the condition number is large, even a small amount of noise in the input would cause the error to blow up! Hence, a problem with a low condition number is said to be well-conditioned, while a problem with a high condition number is said to be ill-conditioned."]},{"cell_type":"markdown","metadata":{"id":"pcnthQrwT6rU"},"source":["In general, suppose that I want to solve $Ax=b$ to find $x$, but I have noisy measurements $\\hat b.$  To do this, I compute $\\hat x = A^{-1} \\hat b.$  \n","**Prove the following**\n","$$\\frac{\\|x-\\hat x\\|}{\\|x\\|} \\le \\kappa \\frac{\\|b-\\hat b\\|}{\\|b\\|}, $$\n","where $\\kappa$ is the condition number of $A.$"]},{"cell_type":"markdown","metadata":{"id":"zZbYpX_jT6rV"},"source":["### Proof\n","We know that $x = A^{-1}b$ and the approximation $\\hat{x} = A^{-1}\\hat{b}$. Hence,\n","$$x-\\hat{x} =  A^{-1}b - A^{-1}\\hat{b} = A^{-1}(b - \\hat{b})$$\n","$$\\|x-\\hat{x}\\| = \\|A^{-1} (b-\\hat{b})\\| ≤ \\|A^{-1}\\|\\|b-\\hat{b}\\|.$$\n","Also, we have $\\|b\\| = \\|Ax\\| ≤ \\|A\\|\\|x\\|$. Using this result with the above equation,\n","$$\\frac{\\|x-\\hat{x}\\|}{\\|A\\|\\|x\\|} ≤ \\|A^{-1}\\|\\frac{\\|b-\\hat{b}\\|}{\\|b\\|}$$\n","$$⇒ \\frac{\\|x-\\hat{x}\\|}{\\|x\\|} ≤ \\|A\\|\\|A^{-1}\\|\\frac{\\|b-\\hat{b}\\|}{\\|b\\|}.$$\n","The term $κ =\\|A\\|\\|A^{-1}\\|$ denotes the condition number of the matrix A and it signifies the magnification in the relative error. "]},{"cell_type":"markdown","metadata":{"id":"qW84oZ4pT6rW"},"source":["## Problem 2 -  Adjoints\n","Suppose you have two functions, `A` an `At` that each implement linear operators.  Write a *randomized* method for checking whether `At` is the adjoint of `A`.  Your test should directly verify the definition of the adjoint\n"," $$\\langle A(x), y \\rangle  = \\langle x, At(y)\\rangle$$\n","where $\\langle \\cdot,\\cdot \\rangle$ denotes the Hermitian inner product.  When $x$ and $h$ happen to be column vectors, this condition becomes\n","  $$A(x)^H y  = x^H At(y)$$\n","  where $x^H$ is the Hermitian transpose of $x.$\n"," The arguments of the checker method are the functions `A` and `At`, and a tuple containing the dimensions of the argument to `A`.  The method returns `True` if the methods are adjoints of one another, and `False` otherwise.\n"," \n"," Your method must work for inputs $x$ of any dimension and shape.\n"," Note: If you choose to use the numpy transpose operator in your solution, remember that this built-in operator is not the Hermitian transpose - It's just a regular transpose without taking the conjugate."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nw5Zlw12T6rY"},"outputs":[],"source":["def check_adjoint(A,At,dims):\n","    # start with this line - create a random input for A()\n","    x = normal(size=dims) + 1j*normal(size=dims)\n","    # FILL IN METHOD BODY HERE\n","    Ax_H = np.conj(A(x))\n","    y = normal(size=Ax_H.shape) + 1j*normal(size=Ax_H.shape)\n","    inner_prod1 = np.sum(Ax_H * y)\n","\n","    x_H = np.conj(x)\n","    Aty = At(y)\n","    inner_prod2 = np.sum(x_H * Aty)\n","    \n","    rel_error = np.linalg.norm(inner_prod1 - inner_prod2)\n","    # End with something like this (change these lines if you want)...\n","    if rel_error < 1e-10:\n","        print('Adjoint Test Passed, rel_diff = %s'%rel_error)\n","        return True\n","    else:\n","        print('Adjoint Test Failed, rel_diff = %s'%rel_error)\n","        return False"]},{"cell_type":"markdown","metadata":{"id":"dtPov7wBT6rZ"},"source":["After filling in the body of your method, run this unit test to make sure it's ok."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B3SfH_egT6ra","executionInfo":{"status":"ok","timestamp":1680181892342,"user_tz":240,"elapsed":272,"user":{"displayName":"Bhargav Kumar Soothram","userId":"14130805473074256710"}},"outputId":"65d9e9e0-2b6e-4486-8878-f1fb8f7a37e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Adjoint Test Failed, rel_diff = 3040.026084495604\n","Adjoint Test Passed, rel_diff = 3.1413794275377845e-11\n","Tests PASSED! You're on your way to understanding linear operators!\n"]}],"source":["# Adjoint unit test - DO NOT MODIFY THIS BLOCK\n","# This method will throw a nasty exception if your code doesn't perform as expected\n","\n","# Test #1: This test should fail because the standard DFT is not self adjoint\n","A = lambda x: fft2(x)\n","At = lambda x: ifft2(x)\n","result = check_adjoint(A,At,(100,200))\n","assert (not result), \"Adjoint test should have failed, but succeeded! Double check your solution!\"   # Throw an exception if the result is unexpected\n","\n","# Test #2: This test should pass though, because F^H = conj(F). \n","A = lambda x: fft2(x)\n","At = lambda x: np.conj(fft2(np.conj(x)))\n","result = check_adjoint(A,At,(100,200))\n","assert result, \"Adjoint test should have succeeded, but failed! Double check your solution!\"  # Throw an exception if the result is unexpected\n","\n","print(\"Tests PASSED! You're on your way to understanding linear operators!\")"]},{"cell_type":"markdown","metadata":{"id":"g_-url2BT6rb"},"source":["## Problem 3 - Convolutions\n","When computing total variation, you need to produce the image gradient, which containts the horizontal and vertical differences between adjacent pixels in a 2d array.\n","Choose the kernels below so that the methods `gradh` and `gradv` produce differences (discrete gradients) in the horizontal and vertical directions.  Remember that convolve2d assumes the middle element of the kernel (array index 1 for a kernel of length 3) is the center of the kernel.  This differs from standard convolutions, in which array index 0 is the center of the kernel.\n","\n","Output i,j of the horizontal gradients should contain `x[i,j+1]-x[i,j]`, while the veritical graident should contain  `x[i+1,j]-x[i,j]`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vZHUw4wZT6rc"},"outputs":[],"source":["# Put your kernels here! \n","kernel_h = [[1, -1, 0]] # Complete this line of code by defining a 3-element, 2d array\n","kernel_v = [[1], [-1], [0]] # Complete this line of code by defining a 3-element, 2d array"]},{"cell_type":"markdown","metadata":{"id":"8MIakS8WT6rc"},"source":["** Now, run the cell below.  It will create the gradient operators using your kernels, and unit test them. Do NOT modify any of the code in the cell below.**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJ4qSdIkT6rd","executionInfo":{"status":"ok","timestamp":1680181896391,"user_tz":240,"elapsed":253,"user":{"displayName":"Bhargav Kumar Soothram","userId":"14130805473074256710"}},"outputId":"e55a03c7-7098-4ccf-8550-621c27f71cde"},"outputs":[{"output_type":"stream","name":"stdout","text":["TESTS PASSED!  YOU ROCK!\n"]}],"source":["# Do not modify ANYTHING in this cell. \n","def gradh(x):\n","    \"\"\"Discrete gradient/difference in horizontal direction\"\"\"\n","    return convolve2d(x,kernel_h, mode='same', boundary='wrap')\n","def gradv(x):\n","    \"\"\"Discrete gradient/difference in vertical direction\"\"\"\n","    return convolve2d(x,kernel_v, mode='same', boundary='wrap')\n","def grad2d(x):\n","    \"\"\"The full gradient operator: compute both x and y differences and return them all.  The x and y \n","    differences are stacked so that rval[0] is a 2D array of x differences, and rval[1] is the y differences.\"\"\"\n","    return np.stack([gradh(x),gradv(x)])\n","\n","# Perform unit tests - this will throw exceptions if your method is screwed up!\n","x = randn(10,20)\n","ghx = gradh(x)\n","assert ghx[0,0] == x[0,1] - x[0,0], 'Failed test 1'\n","assert ghx[0,-1] == x[0,0] - x[0,-1], 'Failed test 2'\n","assert ghx[1,1] == x[1,2] - x[1,1], 'Failed test 3'\n","gvx = gradv(x)\n","assert gvx[0,0] == x[1,0] - x[0,0], 'Failed test 4'\n","assert gvx[-1,0] == x[0,0] - x[-1,0], 'Failed test 5'\n","assert gvx[1,1] == x[2,1] - x[1,1], 'Failed test 6'\n","print('TESTS PASSED!  YOU ROCK!')"]},{"cell_type":"markdown","metadata":{"id":"N3UXSsd4T6re"},"source":["**Now, implement the adjoint/transpose of these operators!**  No looping allowed!  Your implementation of `gradht` and `gradvt` must call `convolve2d` exactly once.  Ideally, you'll only write 1 line of code per line."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CaReEQY-T6rf"},"outputs":[],"source":["# Fill in the implementations of these functions\n","def gradht(x):\n","    \"\"\"Adjoint of gradh\"\"\"\n","    # Your work here!\n","    return convolve2d(x, np.flip(kernel_h), mode='same', boundary='wrap')\n","def gradvt(x):\n","    \"\"\"Adjoint of gradv\"\"\"\n","    # Your work here!\n","    return convolve2d(x, np.flip(kernel_v), mode='same', boundary='wrap')\n","def divergence2d(x):\n","    \"The methods is the adjoint of grad2d.\"\n","    # Your work here!\n","    return gradht(x[0]) + gradvt(x[1])"]},{"cell_type":"markdown","metadata":{"id":"MZ8QEzLsT6rf"},"source":["**After writing the adjoint routines, run the unit test below!**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Pu0oOo-T6rg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680183896432,"user_tz":240,"elapsed":6,"user":{"displayName":"Bhargav Kumar Soothram","userId":"14130805473074256710"}},"outputId":"b26cd7ca-5a55-4eb0-c6ce-601201dad627"},"outputs":[{"output_type":"stream","name":"stdout","text":["Adjoint Test Passed, rel_diff = 1.888293221827313e-14\n","Adjoint Test Passed, rel_diff = 1.4210854715202004e-14\n","Adjoint Test Passed, rel_diff = 1.1374233532693354e-14\n","Unit tests PASSED!  You're getting really good at this!\n"]}],"source":["# Do not modify ANYTHING in this block!\n","is_pass = check_adjoint(gradh, gradht,(10,20))\n","assert is_pass, 'Your gradht method is not the adjoint of gradh.'\n","\n","is_pass = check_adjoint(gradv, gradvt,(10,20))\n","assert is_pass, 'Your gradvt method is not the adjoint of gradv.'\n","\n","is_pass = check_adjoint(grad2d, divergence2d,(10,20))\n","assert is_pass, 'Your divergence2d method is not the adjoint of grad2d.'\n","\n","print(\"Unit tests PASSED!  You're getting really good at this!\")"]},{"cell_type":"markdown","metadata":{"id":"FbBT_juZT6rh"},"source":["## Problem 4 - FFT \n","Now, re-implement these methods using the FFT!\n","Your code must call `np.fft.fft2()` and `np.fft.ifft2(x)`, and you cannot call convolve2d.  No loops allowed!  Remember, when you convolve things using the FFT, you're relying on the convolution theorem.  This theorem assumes the center of the kernel is at index 0.  Also, we're using the 2D DFT here rather than the 1D DFT from your last homework.  All the basic ideas still apply. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n6YNOg7XT6rh"},"outputs":[],"source":["def gradh_fft(x):\n","    \"\"\"Discrete gradient/difference in horizontal direction\"\"\"\n","    # Fill in method body\n","    fft_x = np.fft.fft2(x)\n","    # creating the kernel\n","    kernel = np.zeros(x.shape)\n","    kernel[0, 0] = -1 # centered around 0\n","    kernel[0, -1] = 1 \n","    fft_kernel = np.fft.fft2(kernel)\n","    # reverting from the Fourier domain\n","    ifft_gradh = np.fft.ifft2(fft_x * fft_kernel)\n","    return ifft_gradh\n","\n","def gradv_fft(x):\n","    \"\"\"Discrete gradient/difference in vertical direction\"\"\"\n","    # Fill in method body\n","    fft_x = np.fft.fft2(x)\n","    # creating the kernel\n","    kernel = np.zeros(x.shape)\n","    kernel[0, 0] = -1 # centered around 0\n","    kernel[-1, 0] = 1 \n","    fft_kernel = np.fft.fft2(kernel)\n","    # reverting from the Fourier domain\n","    ifft_gradv = np.fft.ifft2(fft_x * fft_kernel)\n","    return ifft_gradv"]},{"cell_type":"markdown","metadata":{"id":"4KY208DZT6ri"},"source":["**Now, run the unit tests below!**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n8cxRLshT6ri","colab":{"base_uri":"https://localhost:8080/","height":432},"executionInfo":{"status":"error","timestamp":1677196370263,"user_tz":300,"elapsed":147,"user":{"displayName":"Bhargav Kumar Soothram","userId":"14130805473074256710"}},"outputId":"97bb7168-ba56-420f-b367-541728cb7672"},"outputs":[{"output_type":"stream","name":"stdout","text":["Horizontal error =  8.617146016540352e-14\n","Vertical error =  8.626537008856805e-14\n","Tests PASSED!  Wow - you're a linear algebra GENIUS!\n"]},{"output_type":"error","ename":"UnsupportedOperation","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-2938c5a79df0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://www.cs.umd.edu/~tomg/img/important_memes/good_job_cat.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2156\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1558\u001b[0m                     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1560\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mimg_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1561\u001b[0m         return (_pil_png_to_float_array(image)\n\u001b[1;32m   1562\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImagePlugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImageFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fp, filename)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             except (\n\u001b[1;32m    109\u001b[0m                 \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# end of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;31m# get next chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mcid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mcid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnsupportedOperation\u001b[0m: seek"]}],"source":["# Do not modify ANYTHING in this cell\n","# create random array\n","x = randn(100,200)\n","\n","# verify that gradh_fft = gradh\n","h_error = norm(gradh_fft(x)-gradh(x))\n","print('Horizontal error = ', h_error)\n","assert h_error<1e-10, 'Horizontal FFT gradient is incorrect!'\n","\n","# verify that gradv_fft = gradv\n","v_error = norm(gradv_fft(x)-gradv(x))\n","print('Vertical error = ',v_error)\n","assert v_error<1e-10, 'Vertical FFT gradient is incorrect!'\n","\n","print(\"Tests PASSED!  Wow - you're a linear algebra GENIUS!\")\n","\n","f = urllib.request.urlopen(\"https://www.cs.umd.edu/~tomg/img/important_memes/good_job_cat.png\")\n","a = plt.imread(f)\n","fig = plt.imshow(a)\n","fig.axes.get_xaxis().set_visible(False)\n","fig.axes.get_yaxis().set_visible(False)\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}